{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSlLSlq8-gap",
        "outputId": "b913555a-0650-4cf2-9171-ee269176b75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only once\n",
        "!pip install -q pandas numpy scikit-learn xgboost shap lime matplotlib joblib\n"
      ],
      "metadata": {
        "id": "DoZjhsYS_vN0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "credit_risk_pipeline.py\n",
        "Complete pipeline:\n",
        "- Load data from credit_risk_sample.csv\n",
        "- Preprocess (impute, encode, scale)\n",
        "- Train/tune XGBoost (simple randomized search)\n",
        "- Report baseline metrics (AUC, F1, precision, recall, confusion)\n",
        "- Global interpretation: SHAP summary + bar plots\n",
        "- Local interpretation: LIME explanations for 5 cases (3 high-risk, 2 low-risk) near decision boundary\n",
        "- Save model, visuals, and a textual report\n",
        "\n",
        "Assumptions:\n",
        "- data file: credit_risk_sample.csv (in same directory or set DATA_DIR)\n",
        "- borderline cases file optional: borderline_cases.csv (if present, picks specified indices)\n",
        "- target column name default = 'target' (change TARGET_COL if different)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.listdir()\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "DATA_DIR = \".\"  # repo root where credit_risk_sample.csv exists\n",
        "DATA_FILE = os.path.join(DATA_DIR, \"/content/drive/MyDrive/credit_risk_sample.csv\")\n",
        "BORDERLINE_FILE = os.path.join(DATA_DIR, \"borderline_cases.csv\")  # optional\n",
        "TARGET_COL = \"default\"  # change if your target column differs\n",
        "ID_COL = None  # set to 'id' or 'customer_id' if present; else None\n",
        "RANDOM_STATE = 42\n",
        "VIS_DIR = \"visuals\"\n",
        "MODEL_DIR = \"models\"\n",
        "REPORTS_DIR = \"reports\"\n",
        "os.makedirs(VIS_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- DEPENDENCIES ----------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "import xgboost as xgb\n",
        "import shap\n",
        "\n",
        "# LIME import\n",
        "try:\n",
        "    from lime.lime_tabular import LimeTabularExplainer\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Please pip install lime (pip install lime) before running this script.\") from e\n",
        "\n",
        "# ---------- Helper functions ----------\n",
        "def safe_read_csv(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"{path} not found. Put the dataset in the project root or set DATA_DIR.\")\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "def infer_feature_types(df, target_col):\n",
        "    # separate numeric and categorical automatically\n",
        "    features = [c for c in df.columns if c != target_col and c != ID_COL]\n",
        "    num_cols = df[features].select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "    cat_cols = [c for c in features if c not in num_cols]\n",
        "    return num_cols, cat_cols\n",
        "\n",
        "# ---------- Load Data ----------\n",
        "print(\"Loading dataset...\")\n",
        "df = safe_read_csv(DATA_FILE)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "if TARGET_COL not in df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET_COL}' not found in dataset columns: {df.columns.tolist()}\")\n",
        "\n",
        "# If ID column not set, try to detect common ids\n",
        "if ID_COL is None:\n",
        "    for candidate in ['id','ID','customer_id','cust_id']:\n",
        "        if candidate in df.columns:\n",
        "            ID_COL = candidate\n",
        "            break\n",
        "\n",
        "# Quick glance: value counts if target small\n",
        "print(\"Target distribution:\")\n",
        "print(df[TARGET_COL].value_counts(dropna=False))\n",
        "\n",
        "# ---------- Train/Test Split ----------\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[TARGET_COL]).copy()\n",
        "X = df.drop(columns=[TARGET_COL])\n",
        "y = df[TARGET_COL].astype(int)\n",
        "\n",
        "# If ID col present, preserve it in X for later mapping\n",
        "if ID_COL and ID_COL in X.columns:\n",
        "    ids = X[ID_COL].copy()\n",
        "else:\n",
        "    ids = pd.Series(np.arange(len(X)), name=\"index\")\n",
        "\n",
        "# infer feature types\n",
        "num_cols, cat_cols = infer_feature_types(df, TARGET_COL)\n",
        "print(\"Numeric columns:\", num_cols)\n",
        "print(\"Categorical columns:\", cat_cols)\n",
        "\n",
        "# Train-test split (stratify)\n",
        "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
        "    X, y, ids, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# ---------- Preprocessing pipeline ----------\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, num_cols),\n",
        "    ('cat', categorical_transformer, cat_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "# Fit preprocessor on train\n",
        "print(\"Fitting preprocessor...\")\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "# Transform datasets\n",
        "X_train_p = preprocessor.transform(X_train)\n",
        "X_test_p = preprocessor.transform(X_test)\n",
        "\n",
        "# Build feature names after transformation (for SHAP/LIME labeling)\n",
        "ohe_cols = []\n",
        "if len(cat_cols) > 0:\n",
        "    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "    categories = preprocessor.named_transformers_['cat'].named_steps['onehot'].categories_\n",
        "    for col, cats in zip(cat_cols, categories):\n",
        "        for cat in cats:\n",
        "            ohe_cols.append(f\"{col}__{cat}\")\n",
        "feature_names = num_cols + ohe_cols\n",
        "\n",
        "# ---------- Model training: XGBoost ----------\n",
        "print(\"Training XGBoost classifier...\")\n",
        "clf = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=RANDOM_STATE)\n",
        "\n",
        "# quick param grid for RandomizedSearchCV (keeps runtime reasonable)\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "rs = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10, scoring='roc_auc', cv=3, random_state=RANDOM_STATE, n_jobs=-1, verbose=1)\n",
        "rs.fit(X_train_p, y_train)\n",
        "best = rs.best_estimator_\n",
        "print(\"Best params:\", rs.best_params_)\n",
        "print(\"Best CV AUC:\", rs.best_score_)\n",
        "\n",
        "# Predictions & metrics\n",
        "y_pred_proba = best.predict_proba(X_test_p)[:,1]\n",
        "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"F1: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model + preprocessor\n",
        "joblib.dump(best, os.path.join(MODEL_DIR, \"final_model.pkl\"))\n",
        "joblib.dump(preprocessor, os.path.join(MODEL_DIR, \"preprocessor.pkl\"))\n",
        "print(\"Saved model and preprocessor to\", MODEL_DIR)\n",
        "\n",
        "# ---------- Global SHAP analysis ----------\n",
        "print(\"Running SHAP analysis (TreeExplainer)...\")\n",
        "# For XGBoost tree model we can use TreeExplainer\n",
        "explainer = shap.TreeExplainer(best)\n",
        "# Use a sample of train for speed\n",
        "sample_for_shap = X_train_p if X_train_p.shape[0] <= 2000 else X_train_p[np.random.choice(X_train_p.shape[0], 2000, replace=False)]\n",
        "shap_values = explainer.shap_values(sample_for_shap)\n",
        "\n",
        "# summary plot\n",
        "plt.figure(figsize=(10,6))\n",
        "try:\n",
        "    shap.summary_plot(shap_values, features=sample_for_shap, feature_names=feature_names, show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIS_DIR, \"shap_summary.png\"), dpi=150)\n",
        "    plt.close()\n",
        "except Exception as e:\n",
        "    print(\"Could not create SHAP summary plot inline due to environment; saving via matplotlib fallback.\")\n",
        "    # fallback: shap.summary_plot writes to plt if show=False; above should work in most envs\n",
        "\n",
        "# bar plot (mean abs shap)\n",
        "plt.figure(figsize=(8,6))\n",
        "try:\n",
        "    shap.summary_plot(shap_values, features=sample_for_shap, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(VIS_DIR, \"shap_bar.png\"), dpi=150)\n",
        "    plt.close()\n",
        "except Exception as e:\n",
        "    print(\"Could not create SHAP bar plot:\", e)\n",
        "\n",
        "# Save shap values (small sample)\n",
        "np.savez_compressed(os.path.join(MODEL_DIR, \"shap_sample.npz\"), shap=shap_values, features=sample_for_shap)\n",
        "\n",
        "# Also get model's intrinsic feature importance (gain)\n",
        "# mapping feature importance keys to feature names\n",
        "try:\n",
        "    booster = best.get_booster()\n",
        "    fmap = booster.get_score(importance_type='gain')\n",
        "    # booster feature names like 'f0','f1' correspond to our feature ordering\n",
        "    intrinsic_importance = {}\n",
        "    for k,v in fmap.items():\n",
        "        # k like 'f0' -> index\n",
        "        idx = int(k[1:])\n",
        "        if idx < len(feature_names):\n",
        "            intrinsic_importance[feature_names[idx]] = v\n",
        "except Exception:\n",
        "    # fallback: use feature_importances_ (approx)\n",
        "    intrinsic_importance = dict(zip(feature_names, best.feature_importances_))\n",
        "\n",
        "# Sort and keep top 20\n",
        "intrinsic_sorted = sorted(intrinsic_importance.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "\n",
        "# ---------- Local LIME explanations ----------\n",
        "print(\"Running LIME explanations for 5 borderline cases...\")\n",
        "# Prepare a numpy dataset and labels for LIME (uses original scale of preprocessed features)\n",
        "X_all_p = np.vstack([X_train_p, X_test_p])\n",
        "y_all = np.concatenate([y_train, y_test])\n",
        "\n",
        "# Build Lime explainer using the original training data before transform? LIME expects original feature matrix\n",
        "# We'll create a wrapper that explains on preprocessed numeric vector and uses feature names above.\n",
        "explainer_lime = LimeTabularExplainer(\n",
        "    training_data = X_train_p,\n",
        "    feature_names = feature_names,\n",
        "    class_names = ['non_default','default'],\n",
        "    mode = 'classification',\n",
        "    discretize_continuous = False,\n",
        "    random_state = RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Identify borderline samples: those in test set with predicted probability close to 0.5\n",
        "probs = y_pred_proba\n",
        "test_indices = np.arange(len(y_test))\n",
        "# sort by closeness to 0.5\n",
        "dist_to_boundary = np.abs(probs - 0.5)\n",
        "ordered = np.argsort(dist_to_boundary)\n",
        "\n",
        "# Choose 5 samples: top 5 closest to 0.5\n",
        "n_cases = 5\n",
        "chosen_idxs = ordered[:n_cases]\n",
        "# But we want 3 high-risk rejections and 2 low-risk approvals in the set if possible:\n",
        "# define high-risk rejection: model predicts default (pred==1) or prob >0.5; low-risk approval: pred==0\n",
        "chosen_cases = []\n",
        "high_count = 0\n",
        "low_count = 0\n",
        "for idx in ordered:\n",
        "    if len(chosen_cases) >= n_cases:\n",
        "        break\n",
        "    if y_pred[idx] == 1 and high_count < 3:\n",
        "        chosen_cases.append(idx); high_count += 1\n",
        "    elif y_pred[idx] == 0 and low_count < 2:\n",
        "        chosen_cases.append(idx); low_count += 1\n",
        "# If not enough, fill with nearest ones\n",
        "i = 0\n",
        "while len(chosen_cases) < n_cases:\n",
        "    if ordered[i] not in chosen_cases:\n",
        "        chosen_cases.append(ordered[i])\n",
        "    i += 1\n",
        "\n",
        "lime_results = []\n",
        "for i_case, ti in enumerate(chosen_cases):\n",
        "    xi = X_test_p[ti]\n",
        "    yi = y_test.iloc[ti] if hasattr(y_test, 'iloc') else y_test[ti]\n",
        "    prob = y_pred_proba[ti]\n",
        "    pred = y_pred[ti]\n",
        "    exp = explainer_lime.explain_instance(xi, best.predict_proba, num_features=10)\n",
        "    # save figure\n",
        "    fig = exp.as_pyplot_figure()\n",
        "    fig.savefig(os.path.join(VIS_DIR, f\"lime_case_{i_case+1}.png\"), bbox_inches='tight', dpi=150)\n",
        "    plt.close(fig)\n",
        "    # capture explanation as list (feature, weight)\n",
        "    exp_list = exp.as_list()\n",
        "    lime_results.append({\n",
        "        \"case_index_in_test\": int(ti),\n",
        "        \"id\": int(ids_test.iloc[ti]) if hasattr(ids_test, 'iloc') else int(ids_test.iloc[ti]) if hasattr(ids_test, 'iloc') else int(ti),\n",
        "        \"true_label\": int(yi),\n",
        "        \"predicted\": int(pred),\n",
        "        \"probability\": float(prob),\n",
        "        \"explanation\": exp_list\n",
        "    })\n",
        "\n",
        "# ---------- Create textual report ----------\n",
        "report_lines = []\n",
        "report_lines.append(\"Credit Risk Model & Interpretability Report\")\n",
        "report_lines.append(\"=\"*60)\n",
        "report_lines.append(f\"Data file: {DATA_FILE}\")\n",
        "report_lines.append(f\"Rows: {len(df)} | Features: {len(feature_names)}\")\n",
        "report_lines.append(\"\\nMODEL PERFORMANCE (Test set)\")\n",
        "report_lines.append(\"-\"*40)\n",
        "report_lines.append(f\"AUC: {auc:.4f}\")\n",
        "report_lines.append(f\"F1: {f1:.4f}\")\n",
        "report_lines.append(f\"Precision: {precision:.4f}\")\n",
        "report_lines.append(f\"Recall: {recall:.4f}\")\n",
        "report_lines.append(\"Confusion matrix:\")\n",
        "report_lines.append(str(cm))\n",
        "report_lines.append(\"\\nINTRINSIC MODEL FEATURE IMPORTANCE (top 10)\")\n",
        "for feat, val in intrinsic_sorted[:10]:\n",
        "    report_lines.append(f\"{feat}: {val:.6f}\")\n",
        "\n",
        "# SHAP top features (mean abs)\n",
        "try:\n",
        "    mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
        "    shap_ranking = sorted(list(zip(feature_names, mean_abs_shap)), key=lambda x: x[1], reverse=True)[:15]\n",
        "    report_lines.append(\"\\nSHAP TOP FEATURES (global importance)\")\n",
        "    for feat, val in shap_ranking:\n",
        "        report_lines.append(f\"{feat}: {val:.6f}\")\n",
        "except Exception:\n",
        "    report_lines.append(\"\\nSHAP values not available for ranking.\")\n",
        "\n",
        "report_lines.append(\"\\nLIME Local Explanations (selected cases):\")\n",
        "for i_case, res in enumerate(lime_results):\n",
        "    report_lines.append(f\"\\nCase #{i_case+1} (test_index={res['case_index_in_test']}, id={res['id']})\")\n",
        "    report_lines.append(f\"True label: {res['true_label']}, Predicted: {res['predicted']}, Prob(default): {res['probability']:.4f}\")\n",
        "    report_lines.append(\"Top local contributions (feature, weight):\")\n",
        "    for feat, weight in res['explanation']:\n",
        "        report_lines.append(f\"  {feat}: {weight:.4f}\")\n",
        "\n",
        "# Add interpretative comparison (brief)\n",
        "report_lines.append(\"\\nINTERPRETATION / POLICY IMPLICATIONS\")\n",
        "report_lines.append(\"-\"*40)\n",
        "report_lines.append(\"1) SHAP (global) identifies features that most affect predictions across the population.\")\n",
        "report_lines.append(\"2) LIME (local) reveals case-specific drivers; sometimes top global features do not appear in a given local explanation.\")\n",
        "report_lines.append(\"3) For policy: use SHAP to set broad risk rules and LIME to audit individual decisions, especially near-boundary rejections/approvals.\")\n",
        "report_lines.append(\"4) When SHAP and LIME disagree for a borderline case, flag for manual review or request additional data.\")\n",
        "\n",
        "report_text = \"\\n\".join(report_lines)\n",
        "with open(os.path.join(REPORTS_DIR, \"interpretation_report.txt\"), \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "print(\"\\nSaved textual report to\", os.path.join(REPORTS_DIR, \"interpretation_report.txt\"))\n",
        "\n",
        "# Save LIME results as csv/json\n",
        "lime_df_rows = []\n",
        "for r in lime_results:\n",
        "    # flatten explanation to string\n",
        "    expl_str = \"; \".join([f\"{feat} ({weight:.4f})\" for feat, weight in r['explanation']])\n",
        "    lime_df_rows.append({\n",
        "        \"case_index_in_test\": r['case_index_in_test'],\n",
        "        \"id\": r['id'],\n",
        "        \"true_label\": r['true_label'],\n",
        "        \"predicted\": r['predicted'],\n",
        "        \"probability\": r['probability'],\n",
        "        \"explanation\": expl_str\n",
        "    })\n",
        "lime_df = pd.DataFrame(lime_df_rows)\n",
        "lime_df.to_csv(os.path.join(REPORTS_DIR, \"lime_local_explanations.csv\"), index=False)\n",
        "print(\"Saved LIME results to\", os.path.join(REPORTS_DIR, \"lime_local_explanations.csv\"))\n",
        "\n",
        "# Print short summary for user\n",
        "print(\"\\nSummary:\")\n",
        "print(f\"- Model AUC: {auc:.4f}, F1: {f1:.4f}\")\n",
        "print(f\"- SHAP visuals saved: {os.path.join(VIS_DIR,'shap_summary.png')}, {os.path.join(VIS_DIR,'shap_bar.png')}\")\n",
        "for i in range(len(lime_results)):\n",
        "    print(f\"- LIME case {i+1} figure: {os.path.join(VIS_DIR, f'lime_case_{i+1}.png')}\")\n",
        "\n",
        "print(\"\\nAll done. Check the visuals and reports folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nCExJJ2BUGo",
        "outputId": "5dfe939c-605d-4b03-d12c-9e3bd5a4dc8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset shape: (500, 9)\n",
            "Target distribution:\n",
            "default\n",
            "0    402\n",
            "1     98\n",
            "Name: count, dtype: int64\n",
            "Numeric columns: ['loan_amnt', 'annual_income', 'dti', 'credit_score', 'employment_length', 'num_open_accounts', 'recent_missed_payments']\n",
            "Categorical columns: ['purpose']\n",
            "Fitting preprocessor...\n",
            "Training XGBoost classifier...\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Best params: {'subsample': 0.6, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n",
            "Best CV AUC: 0.5179216479839533\n",
            "\n",
            "Test Metrics:\n",
            "AUC: 0.5700\n",
            "F1: 0.0000\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "Confusion matrix:\n",
            " [[80  0]\n",
            " [20  0]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89        80\n",
            "           1       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.40      0.50      0.44       100\n",
            "weighted avg       0.64      0.80      0.71       100\n",
            "\n",
            "Saved model and preprocessor to models\n",
            "Running SHAP analysis (TreeExplainer)...\n",
            "Running LIME explanations for 5 borderline cases...\n",
            "\n",
            "Saved textual report to reports/interpretation_report.txt\n",
            "Saved LIME results to reports/lime_local_explanations.csv\n",
            "\n",
            "Summary:\n",
            "- Model AUC: 0.5700, F1: 0.0000\n",
            "- SHAP visuals saved: visuals/shap_summary.png, visuals/shap_bar.png\n",
            "- LIME case 1 figure: visuals/lime_case_1.png\n",
            "- LIME case 2 figure: visuals/lime_case_2.png\n",
            "- LIME case 3 figure: visuals/lime_case_3.png\n",
            "- LIME case 4 figure: visuals/lime_case_4.png\n",
            "- LIME case 5 figure: visuals/lime_case_5.png\n",
            "\n",
            "All done. Check the visuals and reports folder.\n"
          ]
        }
      ]
    }
  ]
}